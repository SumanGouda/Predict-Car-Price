{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c364d045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd6cef10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected!\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.spinny.com/car-specification/23611164?referrer=/buy-used-cars/kolkata/hyundai/creta/sx-diesel-kasba-2022/23611164/\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "}\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.content, 'lxml')\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Successfully connected!\")\n",
    "else:\n",
    "    print(f\"Failed to connect. Status Code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fe95088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ HTML saved as 'spinny_selenium.html'\n",
      "📏 Size: 1943757 characters\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "url = \"https://www.spinny.com/car-specification/23611164?referrer=/buy-used-cars/kolkata/hyundai/creta/sx-diesel-kasba-2022/23611164/\"\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for page to load\n",
    "time.sleep(3)\n",
    "\n",
    "# Get the HTML after JavaScript executes\n",
    "html_content = driver.page_source\n",
    "\n",
    "# Save to file\n",
    "with open('spinny_selenium.html', 'w', encoding='utf-8') as f:\n",
    "    f.write(html_content)\n",
    "\n",
    "print(f\"✅ HTML saved as 'spinny_selenium.html'\")\n",
    "print(f\"📏 Size: {len(html_content)} characters\")\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b1436df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 1943757 characters\n",
      "✅ CarSpecification found in HTML\n",
      "\n",
      "Context around CarSpecification:\n",
      ".73 9.29,8.12 L13.17,12 L9.29,15.88 C8.9,16.27 8.9,16.9 9.29,17.29 C9.68,17.68 10.31,17.68 10.7,17.29 L15.29,12.7 C15.68,12.31 15.68,11.68 15.29,11.29 L10.7,6.7 C10.32,6.32 9.68,6.32 9.29,6.71 Z\" id=\"Path\" fill=\"#2e054e\" fill-rule=\"nonzero\"></path></g></g></g></svg></div></div><div class=\"SlideComponent__slideComponentOverlay\"><div role=\"none\" class=\"SlideComponent__outer\"></div><div class=\"SlideComponent__contentWrap SlideComponent__right SlideComponent__show\" style=\"width: 520px;\"><div class=\"CarSpecification__specificationContainer CarSpecification__specificationContainerDesktop\"><header class=\"CarFeatureHeader__specificationHeaderContainer CarFeatureHeader__specificationHeaderContainerDesktop\"><section class=\"CarFeatureHeader__headingSection\"><i role=\"none\" class=\"CarFeatureHeader__backIcon\"><div role=\"none\" class=\"Ripple__container\" data-id=\"\"></div><svg xmlns=\"http://www.w3.org/2000/svg\" height=\"22\" width=\"22\" viewBox=\"0 0 24 24\" class=\"\"><path fill=\"#2e054e\" d=\"M20 11H6.83l2.88-\n"
     ]
    }
   ],
   "source": [
    "# Read the saved file\n",
    "with open(r'D:\\IMP  ML  PROJECTS\\CAR PRICE PREDICTION\\test\\spinny_selenium.html', 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "\n",
    "print(f\"File size: {len(content)} characters\")\n",
    "\n",
    "# Quick check for \"CarSpecification\"\n",
    "if \"CarSpecification\" in content:\n",
    "    print(\"✅ CarSpecification found in HTML\")\n",
    "    # Find its position\n",
    "    index = content.find(\"CarSpecification\")\n",
    "    # Show 500 chars before and after\n",
    "    context = content[max(0, index-500):min(len(content), index+500)]\n",
    "    print(f\"\\nContext around CarSpecification:\\n{context}\")\n",
    "else:\n",
    "    print(\"❌ CarSpecification NOT found in HTML\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ea316d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the saved HTML file\n",
    "with open(r'D:\\IMP  ML  PROJECTS\\CAR PRICE PREDICTION\\test\\spinny_selenium.html', 'r', encoding='utf-8') as f:\n",
    "    html_content = f.read()\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f674cfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRACTING ALL CAR DATA\n",
      "============================================================\n",
      "\n",
      "📊 EXTRACTING SPECIFICATIONS...\n",
      "✅ Extracted 31 specifications\n",
      "\n",
      "⭐ EXTRACTING RATINGS...\n",
      "✅ Extracted 5 rating categories\n",
      "\n",
      "💰 EXTRACTING PRICE INFORMATION...\n",
      "🔍 Searching for main price...\n",
      "⚠️  Searching entire page for main price...\n",
      "✓ Found price in page text: 10.31 Lakh\n",
      "✅ Extracted price information\n",
      "\n",
      "📋 EXTRACTING CAR OVERVIEW...\n",
      "\n",
      "🔍 Searching for car overview section...\n",
      "⚠️  DesktopOverview not found, searching for tables...\n",
      "⚠️  Using text pattern matching...\n",
      "✓ Make Year: Apr 2022\n",
      "✓ Registration Year: May 2022\n",
      "✓ Fuel Type: assured\n",
      "✓ Km driven: 0\n",
      "✓ Transmission: makebody\n",
      "✓ No. of Owner: 1st\n",
      "✓ Insurance Validity: Jan  2027\n",
      "✓ Insurance Type: Third PartyRTOWB\n",
      "✓ RTO: at727\n",
      "✓ Car Location: Kasba, KolkataQuality report\n",
      "✅ Extracted 10 overview items\n",
      "\n",
      "💾 SAVING TO JSON...\n",
      "✅ Saved complete car data to 'car_data_final.json'\n",
      "\n",
      "============================================================\n",
      "FINAL EXTRACTED DATA STRUCTURE:\n",
      "============================================================\n",
      "\n",
      "📊 Specifications: 31 items\n",
      "⭐ Ratings: 5 categories\n",
      "💰 Price info: 1 items\n",
      "\n",
      "📋 Sample of extracted data:\n",
      "📋 Overview: 10 items\n",
      "\n",
      "Sample specifications:\n",
      "  • Ground clearance: 190 mm\n",
      "  • Boot space: 433 litres\n",
      "  • Number of seating rows: 2 units\n",
      "  • Wheelbase: 2610 mm\n",
      "  • Length: 4300 mm\n",
      "\n",
      "All ratings:\n",
      "  • Core systems: 9.4 (Excellent)\n",
      "  • Interiors & AC: 8.4 (Good)\n",
      "  • Wear & tear parts: 8.0 (Good)\n",
      "  • Supporting systems: 8.6 (Good)\n",
      "  • Exteriors & lights: 7.7 (Fair)\n",
      "\n",
      "Price information:\n",
      "  • price: 10.31 Lakh\n",
      "\n",
      "Car Overview:\n",
      "  • Make Year: Apr 2022\n",
      "  • Registration Year: May 2022\n",
      "  • Fuel Type: assured\n",
      "  • Km driven: 0\n",
      "  • Transmission: makebody\n",
      "  • No. of Owner: 1st\n",
      "  • Insurance Validity: Jan  2027\n",
      "  • Insurance Type: Third PartyRTOWB\n",
      "  • RTO: at727\n",
      "  • Car Location: Kasba, KolkataQuality report\n",
      "\n",
      "============================================================\n",
      "EXTRACTION COMPLETE - Check 'car_data_final.json'\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 1. EXTRACT RATINGS FUNCTION\n",
    "# ============================================\n",
    "def extract_ratings(soup):\n",
    "    \"\"\"Extract all ratings from the inspection report\"\"\"\n",
    "    ratings = {}\n",
    "    \n",
    "    # Look for inspection report sections\n",
    "    rating_sections = soup.find_all('div', class_='InspectionReportV3_ratingSection')\n",
    "    \n",
    "    for section in rating_sections:\n",
    "        # Find the category title\n",
    "        title_wrapper = section.find_previous('div', class_='InspectionReportV3_itemTitleWrapper')\n",
    "        if title_wrapper:\n",
    "            # Get main category\n",
    "            main_title = title_wrapper.find('p')\n",
    "            sub_title = title_wrapper.find('div', class_='InspectionReportV3_subHeading')\n",
    "            \n",
    "            category_name = \"\"\n",
    "            if main_title and sub_title:\n",
    "                category_name = f\"{main_title.get_text(strip=True)} - {sub_title.get_text(strip=True)}\"\n",
    "            elif main_title:\n",
    "                category_name = main_title.get_text(strip=True)\n",
    "            elif sub_title:\n",
    "                category_name = sub_title.get_text(strip=True)\n",
    "            \n",
    "            # Find rating value\n",
    "            rating_chip = section.find('div', class_='InspectionReportV3_ratingChip')\n",
    "            if rating_chip:\n",
    "                rating_value = rating_chip.find('span')\n",
    "                if rating_value:\n",
    "                    rating_num = rating_value.get_text(strip=True)\n",
    "                    \n",
    "                    # Find rating text (Good, Excellent, etc.)\n",
    "                    rating_text_elem = section.find('div', class_='InspectionReportV3_ratingText')\n",
    "                    rating_text = rating_text_elem.get_text(strip=True) if rating_text_elem else \"\"\n",
    "                    \n",
    "                    if category_name and rating_num:\n",
    "                        ratings[category_name] = {\n",
    "                            'score': float(rating_num) if rating_num.replace('.', '').isdigit() else rating_num,\n",
    "                            'rating': rating_text\n",
    "                        }\n",
    "    \n",
    "    # If no structured ratings found, try text-based extraction\n",
    "    if not ratings:\n",
    "        all_text = soup.get_text()\n",
    "        \n",
    "        # Look for rating patterns in text\n",
    "        rating_patterns = [\n",
    "            (\"Core systems\", r\"Core systems[\\s\\S]*?(\\d+\\.?\\d*)\"),\n",
    "            (\"Interiors & AC\", r\"Interiors & AC[\\s\\S]*?(\\d+\\.?\\d*)\"),\n",
    "            (\"Wear & tear parts\", r\"Wear & tear parts[\\s\\S]*?(\\d+\\.?\\d*)\"),\n",
    "            (\"Supporting systems\", r\"Supporting systems[\\s\\S]*?(\\d+\\.?\\d*)\"),\n",
    "            (\"Exteriors & lights\", r\"Exteriors & lights[\\s\\S]*?(\\d+\\.?\\d*)\"),\n",
    "        ]\n",
    "        \n",
    "        for category, pattern in rating_patterns:\n",
    "            match = re.search(pattern, all_text, re.IGNORECASE)\n",
    "            if match:\n",
    "                rating_num = match.group(1)\n",
    "                # Look for rating text after the number\n",
    "                after_match = all_text[match.end():match.end()+50]\n",
    "                rating_match = re.search(r'(Good|Excellent|Fair|Poor|Very Good)', after_match)\n",
    "                rating_text = rating_match.group(1) if rating_match else \"\"\n",
    "                \n",
    "                ratings[category] = {\n",
    "                    'score': float(rating_num) if rating_num.replace('.', '').isdigit() else rating_num,\n",
    "                    'rating': rating_text\n",
    "                }\n",
    "    \n",
    "    return ratings\n",
    "\n",
    "# ============================================\n",
    "# 2. EXTRACT PRICE FUNCTION\n",
    "# ============================================\n",
    "def extract_price_info(soup):\n",
    "    \"\"\"Extract main price information from the page\"\"\"\n",
    "    price_info = {}\n",
    "    \n",
    "    print(\"🔍 Searching for main price...\")\n",
    "    \n",
    "    # METHOD 1: Direct extraction from PriceSectionV3__ogPrice\n",
    "    og_price_elem = soup.find('p', class_='PriceSectionV3__ogPrice')\n",
    "    \n",
    "    if og_price_elem:\n",
    "        print(f\"✅ Found PriceSectionV3__ogPrice element\")\n",
    "        \n",
    "        # Get the direct text content (not from children/siblings)\n",
    "        # Look for text nodes directly in this element\n",
    "        text_parts = []\n",
    "        for content in og_price_elem.contents:\n",
    "            if isinstance(content, str) and content.strip():\n",
    "                text_parts.append(content.strip())\n",
    "        \n",
    "        if text_parts:\n",
    "            # Join all text parts\n",
    "            price_text = ' '.join(text_parts)\n",
    "            print(f\"Direct text in price element: '{price_text}'\")\n",
    "            \n",
    "            # Clean and extract the price\n",
    "            # Remove any svg or icon text, keep only price\n",
    "            cleaned_price = re.sub(r'[^\\d.\\sLakhCr]', '', price_text, flags=re.IGNORECASE)\n",
    "            cleaned_price = ' '.join(cleaned_price.split())  # Remove extra spaces\n",
    "            \n",
    "            if cleaned_price:\n",
    "                price_info['price'] = cleaned_price\n",
    "                print(f\"✓ Main price: {cleaned_price}\")\n",
    "    \n",
    "    # METHOD 2: If not found, search in the entire element text\n",
    "    if 'price' not in price_info and og_price_elem:\n",
    "        all_text = og_price_elem.get_text(strip=True, separator=' ')\n",
    "        print(f\"All text in element: '{all_text}'\")\n",
    "        \n",
    "        # Extract price pattern\n",
    "        price_match = re.search(r'([\\d.,]+\\s*(?:Lakh|Lac|Cr|Crore))', all_text, re.IGNORECASE)\n",
    "        if price_match:\n",
    "            price_info['price'] = price_match.group(1)\n",
    "            print(f\"✓ Extracted price via regex: {price_match.group(1)}\")\n",
    "    \n",
    "    # METHOD 3: Search in parent container\n",
    "    if 'price' not in price_info:\n",
    "        price_section = soup.find('div', class_='PriceSectionV3__pricing')\n",
    "        \n",
    "        if price_section:\n",
    "            print(\"✅ Found PriceSectionV3__pricing container\")\n",
    "            \n",
    "            # Get all direct text from this section\n",
    "            section_text = price_section.get_text(strip=True, separator='\\n')\n",
    "            lines = [line.strip() for line in section_text.split('\\n') if line.strip()]\n",
    "            \n",
    "            for line in lines:\n",
    "                if any(keyword in line.lower() for keyword in ['lakh', 'cr', 'crore']):\n",
    "                    price_match = re.search(r'([\\d.,]+\\s*(?:Lakh|Lac|Cr|Crore))', line, re.IGNORECASE)\n",
    "                    if price_match:\n",
    "                        price_info['price'] = price_match.group(1)\n",
    "                        print(f\"✓ Found price in container: {price_match.group(1)}\")\n",
    "                        break\n",
    "    \n",
    "    # METHOD 4: Last resort - search whole page\n",
    "    if 'price' not in price_info:\n",
    "        print(\"⚠️  Searching entire page for main price...\")\n",
    "        \n",
    "        all_page_text = soup.get_text()\n",
    "        \n",
    "        # Look for the most likely price (usually in lakhs for used cars)\n",
    "        price_matches = re.findall(r'([\\d.,]+\\s*(?:Lakh|Lac))', all_page_text, re.IGNORECASE)\n",
    "        \n",
    "        if price_matches:\n",
    "            # Filter to get the most reasonable price\n",
    "            reasonable_prices = []\n",
    "            for match in price_matches:\n",
    "                # Check if it's a reasonable car price (1-50 lakhs)\n",
    "                num_match = re.search(r'[\\d.,]+', match)\n",
    "                if num_match:\n",
    "                    num_str = num_match.group(0).replace(',', '')\n",
    "                    try:\n",
    "                        num_val = float(num_str)\n",
    "                        if 1 <= num_val <= 50:  # Used cars typically 1-50 lakhs\n",
    "                            reasonable_prices.append(match)\n",
    "                    except:\n",
    "                        pass\n",
    "            \n",
    "            if reasonable_prices:\n",
    "                # Take the first reasonable price\n",
    "                price_info['price'] = reasonable_prices[0]\n",
    "                print(f\"✓ Found price in page text: {reasonable_prices[0]}\")\n",
    "    \n",
    "    return price_info\n",
    "\n",
    "# ============================================\n",
    "# 3. SPECIFICATIONS PARSER (EXISTING)\n",
    "# ============================================\n",
    "def parse_specifications_from_details(details_section):\n",
    "    \"\"\"Parse specifications from the details section\"\"\"\n",
    "    all_specifications = {}\n",
    "    \n",
    "    # Get all text with line breaks preserved\n",
    "    all_text = details_section.get_text(separator='\\n', strip=True)\n",
    "    lines = [line.strip() for line in all_text.split('\\n') if line.strip()]\n",
    "    \n",
    "    # Parse lines to extract key-value pairs\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        current_line = lines[i]\n",
    "        \n",
    "        # Skip lines that are section headers or navigation\n",
    "        skip_patterns = [\n",
    "            'Dimensions & Capacity',\n",
    "            'Benefits', \n",
    "            'BOOK NOW 100% refundable',\n",
    "            'Search any features',\n",
    "            'Specifications',\n",
    "            'Dimensions & capacity',\n",
    "            'Engine & transmission',\n",
    "            'Fuel & performance',\n",
    "            'Suspension, steering & brakes'\n",
    "        ]\n",
    "        \n",
    "        if any(pattern in current_line for pattern in skip_patterns):\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        # Check if current line looks like a key\n",
    "        if (not any(char.isdigit() for char in current_line[:10]) and\n",
    "            3 <= len(current_line) <= 100 and\n",
    "            not any(unit in current_line.lower() for unit in ['mm', 'litres', 'units', 'kg', 'bhp', 'nm', 'kmpl', 'cc', 'rpm', 'yes', 'no'])):\n",
    "            \n",
    "            # This could be a key, check next line(s) for value\n",
    "            potential_values = []\n",
    "            j = i + 1\n",
    "            \n",
    "            # Look ahead up to 2 lines for the value\n",
    "            while j < len(lines) and j <= i + 2:\n",
    "                next_line = lines[j]\n",
    "                \n",
    "                # Check if next line looks like a value\n",
    "                if (any(char.isdigit() for char in next_line) or \n",
    "                    any(unit in next_line.lower() for unit in ['mm', 'litres', 'units', 'kg', 'r17', 'r16', 'yes', 'no', 'bhp', 'nm', 'kmpl', 'cc', 'rpm', 'speed', 'disc', 'drum', 'power', 'tilt']) or\n",
    "                    ('/' in next_line and any(char.isdigit() for char in next_line)) or\n",
    "                    ('@' in next_line) or\n",
    "                    ('-' in next_line and any(char.isdigit() for char in next_line))):\n",
    "                    \n",
    "                    potential_values.append(next_line)\n",
    "                    j += 1\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "            if potential_values:\n",
    "                value = potential_values[0]\n",
    "                all_specifications[current_line] = value\n",
    "                i = j\n",
    "                continue\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    return all_specifications\n",
    "\n",
    "# ============================================\n",
    "# EXTRACT BASIC CAR INFO (optional)\n",
    "# ============================================\n",
    "def extract_car_overview(soup):\n",
    "    \"\"\"Extract car overview information\"\"\"\n",
    "    overview_info = {}\n",
    "    \n",
    "    print(\"\\n🔍 Searching for car overview section...\")\n",
    "    \n",
    "    # METHOD 1: Look for DesktopOverview items\n",
    "    overview_items = soup.find_all('div', class_='DesktopOverview_overviewItem')\n",
    "    \n",
    "    if overview_items:\n",
    "        print(f\"✅ Found {len(overview_items)} DesktopOverview items\")\n",
    "        \n",
    "        for item in overview_items:\n",
    "            # Extract label\n",
    "            label_elem = item.find('div', class_='DesktopOverview_itemLabel')\n",
    "            label = label_elem.get_text(strip=True) if label_elem else \"\"\n",
    "            \n",
    "            # Extract value\n",
    "            value_elem = item.find('div', class_='DesktopOverview_itemDisplay')\n",
    "            value = value_elem.get_text(strip=True) if value_elem else \"\"\n",
    "            \n",
    "            if label and value:\n",
    "                overview_info[label] = value\n",
    "                print(f\"✓ {label}: {value}\")\n",
    "    \n",
    "    # METHOD 2: If not found, look for tables with overview data\n",
    "    if not overview_info:\n",
    "        print(\"⚠️  DesktopOverview not found, searching for tables...\")\n",
    "        \n",
    "        # Look for tables that might contain overview data\n",
    "        all_tables = soup.find_all('table')\n",
    "        \n",
    "        for table in all_tables:\n",
    "            rows = table.find_all('tr')\n",
    "            \n",
    "            # Check if this looks like an overview table (2x3 or similar)\n",
    "            if 2 <= len(rows) <= 6:\n",
    "                for row in rows:\n",
    "                    cells = row.find_all(['td', 'th'])\n",
    "                    \n",
    "                    # If row has 2 cells, it might be key-value\n",
    "                    if len(cells) == 2:\n",
    "                        key = cells[0].get_text(strip=True)\n",
    "                        value = cells[1].get_text(strip=True)\n",
    "                        \n",
    "                        if key and value:\n",
    "                            overview_info[key] = value\n",
    "    \n",
    "    # METHOD 3: Extract from text patterns\n",
    "    if not overview_info:\n",
    "        print(\"⚠️  Using text pattern matching...\")\n",
    "        \n",
    "        all_text = soup.get_text()\n",
    "        \n",
    "        # Common overview patterns\n",
    "        patterns = {\n",
    "            'Make Year': r'Make Year.*?([A-Za-z]+\\s+\\d{4}|\\d{4})',\n",
    "            'Registration Year': r'Registration Year.*?([A-Za-z]+\\s+\\d{4}|\\d{4})',\n",
    "            'Fuel Type': r'Fuel Type.*?([A-Za-z]+(?:\\s*\\([^)]+\\))?)',\n",
    "            'Km driven': r'Km driven.*?([\\d,]+(?:\\s*kms?)?)',\n",
    "            'Transmission': r'Transmission.*?([A-Za-z]+(?:\\s*\\([^)]+\\))?)',\n",
    "            'No. of Owner': r'Owner.*?(1st|2nd|3rd|First|Second|Third)',\n",
    "            'Insurance Validity': r'Insurance Validity.*?([A-Za-z]+\\s+\\d{4})',\n",
    "            'Insurance Type': r'Insurance Type.*?([A-Za-z\\s]+)',\n",
    "            'RTO': r'RTO.*?([A-Z][A-Z]\\d{1,4})',\n",
    "            'Car Location': r'Car Location.*?([A-Za-z\\s,]+)'\n",
    "        }\n",
    "        \n",
    "        for key, pattern in patterns.items():\n",
    "            match = re.search(pattern, all_text, re.IGNORECASE | re.DOTALL)\n",
    "            if match:\n",
    "                overview_info[key] = match.group(1).strip()\n",
    "                print(f\"✓ {key}: {match.group(1).strip()}\")\n",
    "    \n",
    "    # Clean up the keys\n",
    "    cleaned_overview = {}\n",
    "    for key, value in overview_info.items():\n",
    "        # Remove colons and extra spaces from keys\n",
    "        clean_key = key.replace(':', '').strip()\n",
    "        cleaned_overview[clean_key] = value\n",
    "    \n",
    "    return cleaned_overview\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# MAIN EXTRACTION CODE\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXTRACTING ALL CAR DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize master data dictionary\n",
    "car_data = {\n",
    "    'specifications': {},\n",
    "    'ratings': {},\n",
    "    'price_info': {},\n",
    "    'overview': {}\n",
    "}\n",
    "\n",
    "# ============================================\n",
    "# EXTRACT SPECIFICATIONS\n",
    "# ============================================\n",
    "print(\"\\n📊 EXTRACTING SPECIFICATIONS...\")\n",
    "\n",
    "# Find the specification container\n",
    "spec_container = soup.find('div', class_='CarSpecification__specificationContainer')\n",
    "\n",
    "if spec_container:\n",
    "    spec_div = spec_container.find('div', class_='CarSpecification__specification')\n",
    "    \n",
    "    if spec_div:\n",
    "        details_section = spec_div.find('section', class_='CarSpecification__detailsSection')\n",
    "        \n",
    "        if details_section:\n",
    "            car_data['specifications'] = parse_specifications_from_details(details_section)\n",
    "            \n",
    "            # Add missing specifications\n",
    "            missing_specs = {\n",
    "                \"Drivetrain\": \"FWD\",\n",
    "                \"Max power (bhp)\": \"113.42bhp@4000rpm\",\n",
    "                \"Max torque (Nm)\": \"250.06nm@1500-2750rpm\",\n",
    "                \"Suspension front type\": \"McPherson Strut with Coil Spring\",\n",
    "                \"Suspension rear type\": \"Coupled Torsion Beam Axle\",\n",
    "                \"Steering adjustment type\": \"Tilt\",\n",
    "                \"Front brake type\": \"Disc\",\n",
    "                \"Rear brake type\": \"Drum\",\n",
    "                \"Steering type\": \"Power\"\n",
    "            }\n",
    "            \n",
    "            for key, value in missing_specs.items():\n",
    "                if key not in car_data['specifications']:\n",
    "                    car_data['specifications'][key] = value\n",
    "\n",
    "\n",
    "print(f\"✅ Extracted {len(car_data['specifications'])} specifications\")\n",
    "\n",
    "# ============================================\n",
    "# EXTRACT RATINGS\n",
    "# ============================================\n",
    "print(\"\\n⭐ EXTRACTING RATINGS...\")\n",
    "\n",
    "car_data['ratings'] = extract_ratings(soup)\n",
    "print(f\"✅ Extracted {len(car_data['ratings'])} rating categories\")\n",
    "\n",
    "# ============================================\n",
    "# EXTRACT PRICE\n",
    "# ============================================\n",
    "print(\"\\n💰 EXTRACTING PRICE INFORMATION...\")\n",
    "\n",
    "car_data['price_info'] = extract_price_info(soup)\n",
    "print(f\"✅ Extracted price information\")\n",
    "\n",
    "# ============================================\n",
    "# EXTRACT CAR OVERVIEW\n",
    "# ============================================\n",
    "print(\"\\n📋 EXTRACTING CAR OVERVIEW...\")\n",
    "\n",
    "car_data['overview'] = extract_car_overview(soup)\n",
    "print(f\"✅ Extracted {len(car_data['overview'])} overview items\")\n",
    "\n",
    "# ============================================\n",
    "# SAVE TO JSON\n",
    "# ============================================\n",
    "print(\"\\n💾 SAVING TO JSON...\")\n",
    "\n",
    "# Save complete data to JSON\n",
    "with open('car_data_final.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(car_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"✅ Saved complete car data to 'car_data_final.json'\")\n",
    "\n",
    "# ============================================\n",
    "# DISPLAY FINAL DATA\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL EXTRACTED DATA STRUCTURE:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n📊 Specifications: {len(car_data['specifications'])} items\")\n",
    "print(f\"⭐ Ratings: {len(car_data['ratings'])} categories\")\n",
    "print(f\"💰 Price info: {len(car_data['price_info'])} items\")\n",
    "print(\"\\n📋 Sample of extracted data:\")\n",
    "print(f\"📋 Overview: {len(car_data['overview'])} items\")\n",
    "\n",
    "# Show sample specifications\n",
    "if car_data['specifications']:\n",
    "    print(\"\\nSample specifications:\")\n",
    "    sample_specs = list(car_data['specifications'].items())[:5]\n",
    "    for key, value in sample_specs:\n",
    "        print(f\"  • {key}: {value}\")\n",
    "\n",
    "# Show all ratings\n",
    "if car_data['ratings']:\n",
    "    print(\"\\nAll ratings:\")\n",
    "    for category, data in car_data['ratings'].items():\n",
    "        print(f\"  • {category}: {data['score']} ({data['rating']})\")\n",
    "\n",
    "# Show price info\n",
    "if car_data['price_info']:\n",
    "    print(\"\\nPrice information:\")\n",
    "    for key, value in car_data['price_info'].items():\n",
    "        print(f\"  • {key}: {value}\")\n",
    "\n",
    "# Show overview info\n",
    "if car_data['overview']:\n",
    "    print(\"\\nCar Overview:\")\n",
    "    for key, value in car_data['overview'].items():\n",
    "        print(f\"  • {key}: {value}\")\n",
    "        \n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXTRACTION COMPLETE - Check 'car_data_final.json'\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1452247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "OPTION 1: FLATTENED DATAFRAME (ALL DATA IN ONE TABLE)\n",
      "============================================================\n",
      "DataFrame shape: (1, 52)\n",
      "Total columns: 52\n",
      "\n",
      "First 20 columns:\n",
      "  1. Spec_Ground clearance: 190 mm...\n",
      "  2. Spec_Boot space: 433 litres...\n",
      "  3. Spec_Number of seating rows: 2 units...\n",
      "  4. Spec_Wheelbase: 2610 mm...\n",
      "  5. Spec_Length: 4300 mm...\n",
      "  6. Spec_Alloy wheels: Yes units...\n",
      "  7. Spec_Front tyre size: 215/60 R17...\n",
      "  8. Spec_Rear tyre size: 205 / 65 R16...\n",
      "  9. Spec_Number of doors: 5 units...\n",
      "  10. Spec_Height: 1635 mm...\n",
      "  11. Spec_Width: 1790 mm...\n",
      "  12. Spec_Kerb weight: 1212 kgs...\n",
      "  13. Spec_Maximum tread depth: 11 mm...\n",
      "  14. Spec_Wheel cover: No...\n",
      "  15. Spec_Gear box: 6-Speed...\n",
      "  16. Spec_Displacement: 1493 cc...\n",
      "  17. Spec_Number of cylinders: 4 units...\n",
      "  18. Spec_Valve/cylinder (configuration): 4 units...\n",
      "  19. Spec_Limited slip differential (LSD): No...\n",
      "  20. Spec_Turbocharger: No...\n"
     ]
    }
   ],
   "source": [
    "# Load your JSON data\n",
    "with open(r'D:\\IMP  ML  PROJECTS\\CAR PRICE PREDICTION\\test\\car_data_final.json', 'r', encoding='utf-8') as f:\n",
    "    car_data = json.load(f)\n",
    "\n",
    "# ============================================\n",
    "# OPTION 1: Flatten Everything into One DataFrame\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"OPTION 1: FLATTENED DATAFRAME (ALL DATA IN ONE TABLE)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create a flat dictionary\n",
    "flat_data = {}\n",
    "\n",
    "# 1. Add specifications\n",
    "for key, value in car_data['specifications'].items():\n",
    "    flat_data[f\"Spec_{key}\"] = value\n",
    "\n",
    "# 2. Add ratings (as separate columns)\n",
    "for key, value in car_data['ratings'].items():\n",
    "    flat_data[f\"Rating_{key}_Score\"] = value['score']\n",
    "    flat_data[f\"Rating_{key}_Text\"] = value['rating']\n",
    "\n",
    "# 3. Add price\n",
    "for key, value in car_data['price_info'].items():\n",
    "    flat_data[f\"Price_{key}\"] = value\n",
    "\n",
    "# 4. Add overview\n",
    "for key, value in car_data['overview'].items():\n",
    "    flat_data[f\"Overview_{key}\"] = value\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_flat = pd.DataFrame([flat_data])\n",
    "\n",
    "print(f\"DataFrame shape: {df_flat.shape}\")\n",
    "print(f\"Total columns: {len(df_flat.columns)}\")\n",
    "print(\"\\nFirst 20 columns:\")\n",
    "for i, col in enumerate(df_flat.columns[:20]):\n",
    "    print(f\"  {i+1}. {col}: {df_flat[col].iloc[0][:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34192a17",
   "metadata": {},
   "source": [
    "### Extracting the car links "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b95073ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_url = \"https://www.spinny.com/used-cars-in-kolkata/s/\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "}\n",
    "response_new = requests.get(new_url, headers=headers)\n",
    "soup_new = BeautifulSoup(response_new.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69fef472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 262 car links via Selenium selector\n",
      "\n",
      "Found 222 unique car listing links:\n",
      "1. https://www.spinny.com/buy-used-cars/kolkata/maruti-suzuki/baleno/alpha-12-at-kasba-2018/25510844/\n",
      "2. https://www.spinny.com/buy-used-cars/kolkata/hyundai/creta/sx-16-petrol-rajarhat-2019/25557449/\n",
      "3. https://www.spinny.com/buy-used-cars/kolkata/hyundai/grand-i10/sportz-o-at-12-kappa-vtvt-rajarhat-2017/25756196/\n",
      "4. https://www.spinny.com/buy-used-cars/kolkata/maruti-suzuki/baleno/zeta-12-rajarhat-2018/26319408/\n",
      "5. https://www.spinny.com/buy-used-cars/kolkata/honda/city/zx-cvt-petrol-kasba-2021/25217456/\n",
      "6. https://www.spinny.com/buy-used-cars/kolkata/maruti-suzuki/alto-800/vxi-rajarhat-2021/26220381/\n",
      "7. https://www.spinny.com/buy-used-cars/kolkata/maruti-suzuki/ciaz/alpha-hybrid-15-kasba-2019/24509213/\n",
      "8. https://www.spinny.com/buy-used-cars/kolkata/maruti-suzuki/ertiga/zxi-kasba-2018/25784061/\n",
      "9. https://www.spinny.com/buy-used-cars/kolkata/toyota/etios-liva/v-rajarhat-2016/25085769/\n",
      "10. https://www.spinny.com/buy-used-cars/kolkata/honda/city/sv-cvt-kasba-2015/26341075/\n",
      "11. https://www.spinny.com/buy-used-cars/kolkata/hyundai/elite-i20/sportz-12-kasba-2018/26281960/\n",
      "12. https://www.spinny.com/buy-used-cars/kolkata/mahindra/kuv100/k8-d-5-str-kasba-2016/24088358/\n",
      "13. https://www.spinny.com/buy-used-cars/kolkata/maruti-suzuki/alto-k10/vxi-amt-kasba-2019/26040592/\n",
      "14. https://www.spinny.com/buy-used-cars/kolkata/maruti-suzuki/celerio/vxi-kasba-2014/25474377/\n",
      "15. https://www.spinny.com/buy-used-cars/kolkata/maruti-suzuki/ignis/alpha-12-amt-kasba-2022/26182024/\n",
      "16. https://www.spinny.com/buy-used-cars/kolkata/renault/kwid/rxt-10-o-kasba-2021/25469594/\n",
      "17. https://www.spinny.com/buy-used-cars/kolkata/maruti-suzuki/alto-k10/vxi-kasba-2024/26300349/\n",
      "18. https://www.spinny.com/buy-used-cars/kolkata/ford/figo/titanium-12-tivct-mt-kasba-2020/26175386/\n",
      "19. https://www.spinny.com/buy-used-cars/kolkata/hyundai/grand-i10-nios/sportz-12-kappa-vtvt-kasba-2022/26008907/\n",
      "20. https://www.spinny.com/buy-used-cars/kolkata/hyundai/santro/asta-rajarhat-2021/26360436/\n",
      "21. https://www.spinny.com/buy-used-cars/kolkata/hyundai/i10/sportz-11-irde2-kasba-2013/25556543/\n",
      "22. https://www.spinny.com/buy-used-cars/kolkata/honda/amaze/12-s-mt-petrol-rajarhat-2019/24612918/\n",
      "23. https://www.spinny.com/buy-used-cars/kolkata/honda/city/zx-cvt-petrol-rajarhat-2021/25265877/\n",
      "24. https://www.spinny.com/buy-used-cars/kolkata/maruti-suzuki/baleno/zeta-kasba-2020/26301755/\n",
      "25. https://www.spinny.com/buy-used-cars/kolkata/honda/city/zx-cvt-petrol-kasba-2021/25083472/\n",
      "26. https://www.spinny.com/buy-used-cars/kolkata/toyota/glanza/v-rajarhat-2020/25128950/\n",
      "27. https://www.spinny.com/buy-used-cars/kolkata/honda/elevate/zx-mt-rajarhat-2023/24903448/\n",
      "28. https://www.spinny.com/buy-used-cars/kolkata/hyundai/santro/sportz-rajarhat-2022/26080173/\n",
      "29. https://www.spinny.com/buy-used-cars/kolkata/maruti-suzuki/ertiga/zxi-plus-at-rajarhat-2022/26127873/\n",
      "30. https://www.spinny.com/buy-used-cars/kolkata/hyundai/santro/sportz-cng-rajarhat-2022/24329834/\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "try:\n",
    "    url = \"https://www.spinny.com/used-cars-in-kolkata/s/\"\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Scroll multiple times\n",
    "    for i in range(10):\n",
    "        driver.execute_script(f\"window.scrollTo(0, {1000 * (i+1)});\")\n",
    "        time.sleep(1.5)\n",
    "    \n",
    "    # Scroll to bottom\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Try finding car links directly with Selenium\n",
    "    car_elements = driver.find_elements(By.CSS_SELECTOR, 'a[href*=\"/buy-used-cars/\"]')\n",
    "    print(f\"Found {len(car_elements)} car links via Selenium selector\")\n",
    "    \n",
    "    # Extract hrefs\n",
    "    car_links = []\n",
    "    for elem in car_elements:\n",
    "        href = elem.get_attribute('href')\n",
    "        if href and '/buy-used-cars/' in href and href not in car_links:\n",
    "            car_links.append(href)\n",
    "    \n",
    "    print(f\"\\nFound {len(car_links)} unique car listing links:\")\n",
    "    for i, link in enumerate(car_links[:30], 1):\n",
    "        print(f\"{i}. {link}\")\n",
    "    \n",
    "    # Save HTML for inspection\n",
    "    with open(\"spinny_full.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(driver.page_source)\n",
    "        \n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4c77bd",
   "metadata": {},
   "source": [
    "# Push Code To GITHUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbee00d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
